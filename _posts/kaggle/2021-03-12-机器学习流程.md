---
layout:     post                    # 使用的布局（不需要改）
title:      机器学习流程总结			    # 标题 
subtitle:   	    # 副标题
date:       2021-03-12              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - kaggle
---
# 一、 流程总结
- 导入相关模块
	- 数值计算库 pandas numpy
	- 绘图库 matplatlib seaborn
	- 机器学习库 sklearn
- 数据基本处理
	- 获取数据、查看数据基本信息及分布
	- 确定特征值、目标值
	- 缺失值处理
	- 数据规范化处理、异常值处理
	- 数据集划分（留取法、交叉验证）
- 特征工程
	- 特征提取（字典、文本、图像）
	- 特征预处理（归一化、标准化）
	- 特征降维（特称选取、相关性分析、PCA）
- 机器学习
	- 模型选择
		- 普通模型
		- 集成模型(RF、XGBoost、lightGBM)
	- 参数调优
		- 网格搜索
		- 随机搜索
		- 贝叶斯优化
- 模型评估
	- 回归
		- score得分（R2系数）
		- MAE 平均绝对误差
		- RMSE 均方根误差
	- 分类
		- 准确率
		- 精确率、召回率、F1 score
		- ROC曲线
		- AUC
		- PR曲线
		- logloss
	- 获取最优模型
- 模型预测与导出

# 二、详细介绍
## 1. 导入相关模块
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
```

## 2. 数据基本处理
### 2.1 获取数据及数据查看
```python
# 读取csv

data = pd.read_csv("./data/train.csv")
# 查看头/尾

data.head()
data.tail()

# 查看各列最大、最小、平均值等信息

data.describe()

# 查看列基本信息（类型，多少非null值）

data.info()

# 查看行列信息

data.shape

# 查看去重数量

np.unique(data['row1']).shape

# 查看各个标签的样本个数(即分布信息)

from collections import Counter
Counter(data['target'])

# 图形可视化，查看数据分布

import seaborn as sns
plt.figure(figsize=(10,6))
sns.countplot(data['target'])
plt.show()

# 采样（这里需要先安装Imblearn ， pip3 install imbalanced-learn ）

from imblearn.over_sampling import RandomOverSampler,SMOTE
from imblearn.under_sampling import RandomUnderSampler
# 随机过采样

smo = SMOTE(random_state=0)
X_resampled, y_resampled = smo.fit_resample(X, y)
# 欠采样

rus = RandomUnderSampler(random_state=22)
X_resampled, y_resampled = rus.fit_resample(X, y)

# 合并表格
t = pd.merge(t1,t2,on=['col1','col2'])

# 交叉表合并(查看两列之间的关系)

t = pd.crosstab(table3['user_id'], table3['aisle'])

# 数据截取

data = data[:1000]

```

### 2.2 数据基本处理
```python
# None替换特殊符号

data = data.replace(to_replace='?', value=np.nan)

# 均值填充

data["age"].fillna(data["age"].mean(),inplace=True)

# 删除None

data = data.dropna()

# 确定特征值和目标值

x = data.iloc[:,1:10]
y = data['Class']

# 数据集划分

x_train,x_test,y_train,y_test = train_test_split(x, y, random_state=0, test_size=0.2)

# 采用交叉验证

folder = KFold(n_splits = 4, random_state=0, shuffle = False)
for train, test in folder.split(X, y): 
	print('train:%s | test:%s' %(train, test)) 
	print("")

# 分层采样，确保训练集，测试集中，各类别样本的比例是和原始数据集中的一致。

sfolder = StratifiedKFold(n_splits = 4, random_state = 0, shuffle = False)
for train, test in sfolder.split(X, y): 
 	print('train:%s | test:%s'%(train, test)) 
 	print("")

# 把标签值转为数字

from sklearn.preprocessing import LabelEncoder 
le = LabelEncoder()
y_res = le.fit_transform(y_res)


```

## 3 特征工程
```python
# 特征提取
## 字典特征提取

transfer = DictVectorizer(sparse=False)
x_train = transfer.fit_transform(x_train.to_dict(orient="records"))
x_test = transfer.fit_transform(x_test.to_dict(orient="records"))

# 独热编码(适合分类值较少的特征)

train['matchType'].unique()
train = pd.get_dummies(train, columns=['matchType'])

# 文本特征（参考：特征工程-〉特征提取）

# 特征降维
transfer = PCA(n_components=0.9)
data = transfer.fit_transform(table)

```

## 4. 机器学习
```python
# 参数调优
# 网格搜索

from sklearn.model_selection import GridSearchCV
estimator = lgb.LGBMRegressor(num_leaves=31)
param_grid = {
    'learning_rate': [0.01, 0.1, 1],
    'n_estimators': [20, 40, 60, 100, 200, 300]
}
gbm = GridSearchCV(estimator, param_grid, cv=5, n_jobs=-1) 
gbm.fit(X_train, y_train)

# 最优参数
print("在交叉验证中验证的最好结果:\n", estimator.best_score_) 
print("最好的参数模型:\n", estimator.best_estimator_) 
print("每次交叉验证后的验证集准确率结果和训练集准确率结果:\n",estimator.cv_results_)

```

## 5. 模型评估
```python
# 平均绝对误差

from sklearn.metrics import mean_absolute_error
y_pred = gbm.predict(X_valid)
mean_absolute_error(y_valid, y_pred)

# score得分(R2系数)

y_pre = m2.predict(X_valid)
m2.score(X_valid, y_valid)

# logloss(用于分类问题)

from sklearn.metrics import log_loss
y_pre_prob = rf3.predict_proba(x_test)
log_loss(y_test, y_pre_prob)

```

## 6. 模型导出
```python
# 保存模型

from sklearn.externals import joblib
joblib.dump(model, './test.pkl')

# 加载模型 

estimator = joblib.load(‘test.pkl’)

```

