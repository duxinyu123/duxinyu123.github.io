---
layout:     post                    # 使用的布局（不需要改）
title:      图像检测-中		    # 标题 
subtitle:   RCNN、Fast-RCNN、Faster-RCNN   	# 副标题
date:       2021-03-26              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - CV
---
# 一、overfeat模型
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhcks46fj30m70f2gud.jpg)

# 二、RCNN
## 1. 算法流程
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhfyyuswj30lf07bqb0.jpg)

- 候选区域生成：
	- 使用选择性搜索（Selective Search）的方法找出图片中可能存在目标的侯选区域
- CNN网络提取特征：
	- 选取预训练卷积神经网网络（AlexNet或VGG）用于进行特征提取。
- 目标分类：
	- 训练支持向量机（SVM）来辨别目标物体和背景，对每个类别，都要训练一个二元SVM。
- 目标定位：
	- 训练一个线性回归模型，为每个辨识到的物体生成更精确的边界框。

## 2. 候选区域生成

在**选择性搜索（SelectiveSearch，SS）中**，使用语义分割的方法，它将颜色、边界、纹理等信息作为合并条件，采用多尺度的综合方法，将图像在像素级上划分出一系列的区域，这些区域要远远少于传统的滑动窗口的穷举法产生的候选区域。
SelectiveSearch在一张图片上提取出来约2000个侯选区域，需要注意的是这些候选区域的长宽不固定。而使用CNN提取候选区域的特征向量，需要接受固定长度的输入，所以需要对候选区域做一些尺寸上的修改。



## 3. CNN网络提取特征
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhibla0rj30l605yjue.jpg)
采用预训练模型(AlexNet或VGG)在生成的候选区域上进行特征提取，将提取好的特征保存在磁盘中，用于后续步骤的分类和回归。

1.全连接层的输入数据的尺寸是固定的，因此在将候选区域送入CNN网络中时，需进行裁剪或变形为固定的尺寸，在进行特征提取。
2.预训练模型在ImageNet数据集上获得，最后的全连接层是1000，在这里我们需要将其改为N+1(N为目标类别的数目，例如VOC数据集中N=20，coco数据集中N=80，1是加一个背景)后，进行微调即可。
3.利用微调后的CNN网络，提取每一个候选区域的特征，获取一个4096维的特征，一幅图像就是2000x4096维特征存储到磁盘中。

## 4. 目标分类(SVM)
假设我们要检测猫狗两个类别，那我们需要训练猫和狗两个不同类别的SVM分类器，然后使用训练好的分类器对一幅图像中2000个候选区域的特征向量分别判断一次，这样得出[2000, 2]的得分矩阵，如下图所示：
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhj52avvj30m10eqn5e.jpg)
对于N个类别的检测任务，需要训练N（目标类别数目）个SVM分类器，对候选区域的特征向量（4096维）进行二分类，判断其是某一类别的目标，还是背景来完成目标分类。

## 5. 目标定位
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhjnh9znj30lm0l5qeo.jpg)

## 6. 算法总结
- 训练阶段多，训练耗时： 
	- 微调CNN网络+训练SVM+训练边框回归器。
- 预测速度慢: 
	- 使用GPU, VGG16模型处理一张图像需要47s。
- 占用磁盘空间大：
	- 5000张图像产生几百G的特征文件。
- 数据的形状变化：
	- 候选区域要经过缩放来固定大小，无法保证目标的不变形

# 三、Fast-RCNN
- 考虑到R-CNN存在的问题，2015年提出了一个改善模型:Fast R-CNN。 相比于R-CNN, Fast R-CNN主要在以下三个方面进行了改进：
	- 1、**提高训练和预测的速度**
		- R-CNN首先从测试图中提取2000个候选区域，然后将这2000个候选区域分别输入到预训练好的CNN中提取特征。由于候选区域有大量的重叠，这种提取特征的方法，就会重复的计算重叠区域的特征- 。在Fast-RCNN中，将整张图输入到CNN中提取特征，将候选区域映射到特征图上，这样就避免了对图像区域进行重复处理，提高效率减少时间。
	- 2、**不需要额外的空间保存CNN网络提取的特征向量**
		- RCNN中需要将提取到的特征保存下来，用于为每个类训练单独的SVM分类器和边框回归器。在Fast-RCNN中，将类别判断和边框回归统一使用CNN实现，不需要在额外的空间存储特征。
	- 3、**不在直接对候选区域进行缩放**
		- RCNN中需要对候选区域进行缩放送入CNN中进行特征提取，在Fast-RCNN中使用ROIpooling的方法进行尺寸的调整。

## 1. 算法流程
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhm7ph0dj30lp0inn5s.jpg)

### 1.1 候选区域生成
与RCNN中一样，不再赘述

### 1.2 CNN网络特征提取
与RCNN中一样，使用预训练模型进行特征提取

### 1.3 ROI Pooling
> 只对感兴趣的特征进行pooling
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhu2h743j30lf0iethb.jpg)

### 1.4 目标分类和回归
原网络的最后一个全连接层替换为两个同级层:K+1个类别的SoftMax分类层和边框的回归层
![](https://tva1.sinaimg.cn/large/008eGmZEly1goxhnh3zjzj30md0ildoh.jpg)

## 2. 模型训练
![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzaswp4cj30l90c0q4z.jpg)

## 3. 模型预测
- fastRCNN的工作流程描述如下：
	- 输入图像；
	- 图像被送入到卷积网络进行特征提取，将通过选择性搜索获取的候选区域映射到特征图中；
	- 在特征图上Rol中应用RoIPooling，获取尺寸相同的特征向量；
	- 将这些区域传递到全连接的网络中进行分类和回归，得到目标检测的结果。

## 4. 模型总结
- Fast R-CNN是对R-CNN模型的一种改进：
	- CNN网络不再对每个候选区域进行特征提取，而是直接对整张图像进行出路，这样减少了很多重复计算。
	- 用ROI pooling进行特征的尺寸变换，来满足FC全连接层对输入数据尺度的要求。
	- 将目标的回归和分类统一在一个网络中，使用FC+softmax进行目标分类，使用FC Layer进行目标框的回归。
在Fast R-CNN中使用的目标检测识别网络，在速度和精度上都有了不错的结果。不足的是，其候选区域提取方法耗时较长，而且和目标检测网络是分离的，并不是端到端的，在201- 6年又提出了Faster-RCNN模型用于目标检测，在接下来的课程中我们着重介绍Faster-RCNN网络的原理与实现。


# 四、Faster-RCNN
在R-CNN和Fast RCNN的基础上，在2016年提出了Faster RCNN网络模型，在结构上，Faster RCNN已经将候选区域的生成，特征提取，目标分类及目标框的回归都整合在了一个网络中，综合性能有较大提高，在检测速度方面尤为明显。接下来我们给大家详细介绍fasterRCNN网络模型。网络基本结构如下图所示：

![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzedqr4jj30lz0lowmu.jpg)
## 1. 网络工作流程
![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzffimw9j30l60h2gzg.jpg)

- 1、特征提取：将整个图像缩放至固定的大小输入到CNN网络中进行特征提取，得到特征图。
- 2、候选区域提取：输入特征图，使用区域生成网络RPN，产生一些列的候选区域
- 3、ROIPooling: 与Fast RCNN网络中一样，使用最大池化固定候选区域的尺寸，送入后续网络中进行处理
- 4、目标分类和回归：与Fast RCNN网络中一样，使用两个同级层:K+1个类别的SoftMax分类层和边框的回归层，来完成目标的分类和回归。
- Faster R-CNN的流程与Fast R-CNN的区别不是很大，重要的改进是使用RPN网络来替代选择性搜索获取候选区域，所以我们可以将Faster R-CNN网络看做RPN和Fast R-CNN网络的结合。

### 1.1 数据加载
```python
# 导入相关工具包

# 获取VOC数据使用

from detection.datasets import pascal_voc
# 绘图

import matplotlib.pyplot as plt
import numpy as np
# 模型构建

from detection.models.detectors import faster_rcnn
import tensorflow as tf
# 图像展示

import visualize
```

```python
# 实例化voc数据集的类，获取送入网络中的一张图片

pascal = pascal_voc.pascal_voc("train")
# image：送入网络中的数据，imagemeta:图像的元信息

image,imagemeta,bbox,label = pascal[218]
# 图像的均值和标准差

img_mean = (122.7717, 115.9465, 102.9801)
img_std = (1., 1., 1.)
# RGB图像(反标准化操作，获取原图像)

rgd_image= np.round(image+img_mean).astype(np.uint8)

# 获取原始图像

from detection.datasets.utils import get_original_image
ori_img = get_original_image(image[0],imagemeta[0],img_mean)

# 展示原图像和送入网络中图像

rgd_image= np.round(image+img_mean).astype(np.uint8)
fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)
axes[0].imshow(ori_img.astype('uint8'))
axes[0].set_title("原图像")
axes[1].imshow(rgd_image[0])
axes[1].set_title("送入网络中的图像")
plt.show()
```
![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzjrosntj30li0ann5p.jpg)



### 1.2 模型加载
```python
# coco数据集的class，共80个类别：人，自行车，火车，。。。

classes = ['bg', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
           'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']

# 实例化模型

model = faster_rcnn.FasterRCNN(num_classes=len(classes))

model((image,imagemeta,bbox,label),training=True)
# 加载训练好的weights

model.load_weights("weights/faster_rcnn.h5")
```
![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzkn8417j30lv0cogp0.jpg)

### 1.3 模型预测过程
```python
# RPN获取候选区域：输入图像和对应的元信息，输出是候选的位置信息

proposals = model.simple_test_rpn(image[0],imagemeta[0])

# 绘制在图像上(将proposal绘制在图像上)

visualize.draw_boxes(rgd_image[0],boxes=proposals[:,:4]*1216)
plt.show()

# rcnn进行预测,得到的是原图像的检测结果：

# 输入：要检测的送入网络中的图像，图像的元信息，RPN产生的候选区域
# 输出：目标检测结果：检测框(相对于原图像)，类别，置信度

res = model.simple_test_bboxes(image[0],imagemeta[0],proposals)

# 将检测结果绘制在图像上

visualize.display_instances(ori_img,res['rois'],res['class_ids'],classes,res['scores'])
plt.show()
```
![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzlvh638j30kr0flqlh.jpg)

## 2. 模型结构详解
![](https://tva1.sinaimg.cn/large/008eGmZEly1gozzngovb7j30lr0c4k1e.jpg)
- Backbone：Backbone由CNN卷积神经网络构成，常用的是VGG和resnet,用来提取图像中的特征，获取图像的特征图。该特征图被共享用于后续RPN层生成候选区域和ROIPooli- ng层中。
- RPN网络：RPN网络用于生成候选区域，用于后续的目标检测。
- Roi Pooling: 该部分收集图像的特征图和RPN网络提取的候选区域位置，综合信息后获取固定尺寸的特征，送入后续全连接层判定目标类别和确定目标位置。
- 目标分类与回归: 该部分利用ROIpooling输出特征向量计算候选区域的类别，并通过回归获得检测框最终的精确位置。

### 2.1 backbone(骨架网络)

## 3. FasterRCNN的训练

## 4. 端到端的训练