---
layout:     post                    # 使用的布局（不需要改）
title:      图像分割		        # 标题 
subtitle:   FCN、UNet、Mask RCNN  	# 副标题
date:       2021-04-01              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - CV
---
# 一、图像分割定义
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43ct9hhej30mc0j27dk.jpg)
- 这三个任务对图像的理解逐步深入。假设给定一张输入图像，
- 
- 图像分类旨在判断该图像所属类别。
- 目标检测是在图像分类的基础上，进一步判断图像中的目标具体在图像的什么位置，通常是以外包矩形(bounding box)的形式表示。
- 图像分割是目标检测更进阶的任务，目标检测只需要框出每个目标的包围盒，语义分割需要进一步判断图像中哪些像素属于哪个目标。但是，语义分割不区分属于相同类别的不同实例。- 如上图所示，当图像中有多个cube时，语义分割会将所有立方体整体的所有像素预测为“cube”这个类别。与此不同的是，**实例分割** 需要区分出哪些像素属于第一个cube、哪些像素属于第二个cube……。

![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43dni05sj30lw0e97a4.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43e0i8z7j30mo0d1qff.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43e95seij30lr0d4gqt.jpg)

## 1. 任务类型
> 这里是基于传统CV的方式分割，后面会介绍神经网络分割

![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43esopxhj30kh0a5tep.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43fmzbb2j30m60fgjx5.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43fvpvxbj30lt0btjzn.jpg)

- 语义分割就是把图像中每个像素赋予一个类别标签，如下图我们将图像中的像素分类为人，羊，狗，草地即可。
- 实例分割，相对于语义分割来讲，不仅要区分不同类别的像素，还需要需要对同一类别的不同个体进行区分。如下图所示，不仅需要进行类别的划分，还要将各个个体划分出来：羊1，羊2，羊3，羊4，羊5等。

## 2. 常用开源数据集
图像分割常用的数据集是PASCAL VOC，城市风光Cityscapes数据集，coco数据集等。


## 3. 评价指标
### 3.1 像素精度
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43hwf9lrj30m108i0tr.jpg)

### 3.2 平均像素精度
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43i3lso4j30ls06pmxv.jpg)

### 3.3 平均交并比
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43icboedj30lt07nq4k.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp43io4tn4j30lt0jotca.jpg)

# 二、语义分割 - FCN
FCN（Fully Convolutional Networks） 用于图像语义分割，自从该网络提出后，就成为语义分割的基本框架，后续算法基本都是在该网络框架中改进而来。
对于一般的分类CNN网络，如VGG和Resnet，都会在网络的最后加入一些全连接层，经过softmax后就可以获得类别概率信息。
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gbqjso1j30l80iln4d.jpg)
简而言之，FCN和CNN的区别就是：CNN卷积层之后连接的是全连接层；FCN卷积层之后仍连接卷积层，输出的是与输入大小相同的特征图。
## 1. 网络结构
### 1.1 全链接部分
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gfgear8j30l40kt0x8.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gfnqf1rj30l20cgadt.jpg)

### 1.2 上采样部分
上采样部分将最终得到的特征图上采样得到原图像大小的语义分割结果。

在这里采用的上采样方法是反卷积（Deconvolution），也叫做转置卷积（Transposed Convolution）：

反卷积是一种特殊的正向卷积
通俗的讲，就是输入补0+卷积。先按照一定的比例通过补0来扩大输入图像的尺寸，再进行正向卷积即可。
如下图所示：输入图像尺寸为3x3，卷积核kernel为3x3，步长strides=2，填充padding=1
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4ggolflrj30hj06wmxv.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4ggz0ilmj30lo0k4dqw.jpg)

## 2. 跳层链接
如果只利用反卷积对最后一层的特征图进行上采样的到原图大小的分割，由于最后一层的特征图太小，会损失很多细节。因而提出增加Skips结构将最后一层的预测（有更富的全局信息）和更浅层（有更多的局部细节）的预测结合起来。
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gheqnewj30kz0eejw5.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4ghp86q1j30lh0klgv9.jpg)

## 3. 总结
- 优点
	- 端到端的，可以接受任意大小的输入图像尺寸，比较高效。
- 局限性
	- 得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊的，对图像中的细节不敏感。
	- 而且在对各个像素进行分类时，没有考虑像素与像素之间的关系。

# 三、UNet
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gijiodrj30l10f178o.jpg)
- 整个网络由编码部分（左） 和 解码部分（右）组成，类似于一个大大的U字母，具体介绍如下：
	- 1、编码部分是典型的卷积网络架构：
		- 架构中含有着一种重复结构，每次重复中都有2个 3 x 3卷积层、非线性ReLU层和一个 2 x 2 max pooling层（stride为2）。（图中的蓝箭头、红箭头，没画ReLu）
		- 每一次下采样后我们都把特征通道的数量加倍
	- 2、解码部分也使用了类似的模式：
		- 每一步都首先使用反卷积(up-convolution)，每次使用反卷积都将特征通道数量减半，特征图大小加倍。（图中绿箭头）
		- 反卷积过后，将反卷积的结果与编码部分中对应步骤的特征图拼接起来。（白/蓝块）
		- 编码部分中的特征图尺寸稍大，将其修剪过后进行拼接。（左边深蓝虚线）
		- 对拼接后的map再进行2次3 x 3的卷积。（右侧蓝箭头）
		- 最后一层的卷积核大小为1 x 1，将64通道的特征图转化为特定类别数量（分类数量）的结果。（图中青色箭头）

# 四、UNet 案例
## 1. 任务及数据集简介
使Oxford-IIIT Pet Dataset宠物图像分割数据集，包含37种宠物类别，其中有12种猫的类别和25种狗的类别，每个类别大约有200张图片，所有图像都具有品种，头部ROI和像素级分割的标注，如下图所示：
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gmxceu3j30ls0axk3d.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp4gnc3v2gj30l60o8h7r.jpg)

## 2. 数据集获取
```python
# 在进行模型构建之前，我们将读取数据集，导入相应的工具包：

import os
from IPython.display import Image, display
from tensorflow.keras.preprocessing.image import load_img
import PIL
from PIL import ImageOps


# 路径及相关参数设置

# 图片位置

input_dir = "segdata/images/"
# 标注信息位置

target_dir = "segdata/annotations/trimaps/"
# 图像大小设置及类别信息

img_size = (160, 160)
batch_size = 32
num_classes = 4
# 图像的路径

input_img_paths = sorted(
    [
        os.path.join(input_dir, fname)
        for fname in os.listdir(input_dir)
        if fname.endswith(".jpg")
    ]
)
# 目标值路径

target_img_paths = sorted(
    [
        os.path.join(target_dir, fname)
        for fname in os.listdir(target_dir)
        if fname.endswith(".png") and not fname.startswith(".")
    ]
)

# 显示一个图像

display(Image(filename=input_img_paths[10]))

# 显示标注图像

img = PIL.ImageOps.autocontrast(load_img(target_img_paths[10]))
display(img)
```

构建数据集生成器:
```python
from tensorflow import keras
import numpy as np
from tensorflow.keras.preprocessing.image import load_img

# 数据集获取：

class OxfordPets(keras.utils.Sequence):

    # 在__init__方法中指定batch_size,img_size,input_img_paths,target_img_paths

    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):
        self.batch_size = batch_size  # 批量大小
        self.img_size = img_size  # 图像大小
        self.input_img_paths = input_img_paths  # 输入图像路径
        self.target_img_paths = target_img_paths  # 标注图像路径

    def __len__(self):
        # 计算迭代次数

        return len(self.target_img_paths) // self.batch_size

    def __getitem__(self, idx):
        """
        获取每一个batch数据
        """

        i = idx * self.batch_size
        # 获取输入的图像数据

        batch_input_img_paths = self.input_img_paths[i: i + self.batch_size]
        # 获取标签数据

        batch_target_img_paths = self.target_img_paths[i: i + self.batch_size]
        # 构建特征值数据：获取图像数据中每个像素的数据存储在x中

        x = np.zeros((batch_size,) + self.img_size + (3,), dtype="float32")
        for j, path in enumerate(batch_input_img_paths):
            img = load_img(path, target_size=self.img_size)
            x[j] = img
        # 构建目标值数据：获取标注图像中每个像素中的数据存在y中
        
        y = np.zeros((batch_size,) + self.img_size + (1,), dtype="uint8")
        for j, path in enumerate(batch_target_img_paths):
            img = load_img(path, target_size=self.img_size,
                           color_mode="grayscale")
            y[j] = np.expand_dims(img, 2)
        return x, y
```

## 3. 模型构建

## 4. 模型训练

## 5. 模型预测

# 五、实例分割 - Mask RCNN