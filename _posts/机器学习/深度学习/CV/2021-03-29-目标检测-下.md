---
layout:     post                    # 使用的布局（不需要改）
title:      图像检测-下		        # 标题 
subtitle:   YOLO,YOLO-V2,YOLO-V3,YOLO-V4   	# 副标题
date:       2021-03-29              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - CV
---
# 一、YOLO算法
Yolo算法采用一个单独的CNN模型实现end-to-end的目标检测，核心思想就是利用整张图作为网络的输入，直接在输出层回归 bounding box（边界框） 的位置及其所属的类别，整个系统如下图所示：
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp111ep5ipj30lu07pn29.jpg)
## 1. 算法思想
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp112hc2wdj30lt0b0dhz.jpg)
Yolo意思是You Only Look Once，它并没有真正的去掉候选区域，而是创造性的将候选区和目标分类合二为一，看一眼图片就能知道有哪些对象以及它们的位置。

Yolo模型采用预定义预测区域的方法来完成目标检测，具体而言是将原始图像划分为 7x7=49 个网格（grid），每个网格允许预测出2个边框（bounding box，包含某个对象的矩形框），总共 49x2=98 个bounding box。我们将其理解为98个预测区，很粗略的覆盖了图片的整个区域，就在这98个预测区中进行目标检测。



## 2. 网络架构
YOLO的结构非常简单，就是单纯的卷积、池化最后加了两层全连接，从网络结构上看，与前面介绍的CNN分类网络没有本质的区别，最大的差异是输出层用线性函数做激活函数，因为需要预测bounding box的位置（数值型），而不仅仅是对象的概率。所以粗略来说，YOLO的整个结构就是输入图片经过神经网络的变换得到一个输出的张量，如下图所示：

![](https://tva1.sinaimg.cn/large/008eGmZEly1gp1135bpjhj30ly0cg78i.jpg)

### 2.1 网格输入
网络的输入是原始图像，唯一的要求是缩放到448x448的大小。主要是因为Yolo的网络中，卷积层最后接了两个全连接层，全连接层是要求固定大小的向量作为输入，所以Yolo的输入图像的大小固定为448x448。

### 2.2 网格输出
网络的输出就是一个7x7x30 的张量（tensor）
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp1147m873j30m50g2jx1.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp114lix34j30lt0gqdns.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp114tk5myj30lb0brgnx.jpg)

## 3. 模型训练
在进行模型训练时，我们需要构造训练样本和设计损失函数，才能利用梯度下降对网络进行训练。
### 3.1 训练样本的构建
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp115tug0hj30l50fgala.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp1165o7unj30ll0hoadu.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp116f41h4j30l106gdh7.jpg)

### 3.2 损失函数
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp116vqmslj30li09bq57.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp1177zy9nj30lu0fr435.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp117giz1xj30kz0cnafe.jpg)
### 3.3 模型训练
Yolo先使用ImageNet数据集对前20层卷积网络进行预训练，然后使用完整的网络，在PASCAL VOC数据集上进行对象识别和定位的训练。
Yolo的最后一层采用线性激活函数，其它层都是Leaky ReLU。训练中采用了drop out和数据增强（data augmentation）来防止过拟合.

## 4. 模型预测
将图片resize成448x448的大小，送入到yolo网络中，输出一个 7x7x30 的张量（tensor）来表示图片中所有网格包含的对象（概率）以及该对象可能的2个位置（bounding box）和可信程度（置信度）。在采用NMS（Non-maximal suppression，非极大值抑制）算法选出最有可能是目标的结果。

## 5. YOLO总结
- 优点：
	- 速度非常快，处理速度可以达到45fps，其快速版本（网络较小）甚至可以达到155fps。
	- 训练和预测可以端到端的进行，非常简便。
- 缺点：
	- 准确率会打折扣
	- 对于小目标和靠的很近的目标检测效果并不好

# 二、YOLO-V2
## 1. better(从预测更准确)
- batch normalization
	- 批标准化有助于解决反向传播过程中的梯度消失和梯度爆炸问题，降低对一些超参数的敏感性，并且每个batch分别进行归一化的时候，起到了一定的正则化效果，从而能够获得更好的收敛速度和收敛效果。
- 使用高分辨率图像微调分类模型
	- 采用 224x224 图像进行分类模型预训练后，再采用 448x448 的高分辨率样本对分类模型进行微调（10个epoch），使网络特征逐渐适应 448x448 的分辨率。然后再使用 448x448 的检测样本进行训练，缓解了分辨率突然切换造成的影响。
- 采用Anchor Boxes
	- YOLO2每个grid采用5个先验框
- 聚类提取anchor尺度
	- YOLO2尝试统计出更符合样本中对象尺寸的先验框，这样就可以减少网络微调先验框到实际位置的难度;
	- YoloV2选择了聚类的五种尺寸最常使用的anchor box。
- 边框位置的预测
	- ![](https://tva1.sinaimg.cn/large/008eGmZEly1gp11hgyskhj30gi07l3z7.jpg)

- 细粒度特征融合
	- ![](https://tva1.sinaimg.cn/large/008eGmZEly1gp11ht68ujj30ll0cptbp.jpg)

- 多尺度训练
	- YOLO2中没有全连接层，可以输入任何尺寸的图像。

## 2. faster(速度更快)
yoloV2提出了Darknet-19（有19个卷积层和5个MaxPooling层）网络结构作为特征提取网络。DarkNet-19比VGG-16小一些，精度不弱于VGG-16，但浮点运算量减少到约⅕，以保证更快的运算速度。
![](https://tva1.sinaimg.cn/large/008eGmZEly1gp11j2e9cbj30la0cn0w2.jpg)

## 3. stronger(识别对象更多)
VOC数据集可以检测20种对象，但实际上对象的种类非常多，只是缺少相应的用于对象检测的训练样本。YOLO2尝试利用ImageNet非常大量的分类样本，联合COCO的对象检测数据集一起训练，使得YOLO2即使没有学过很多对象的检测样本，也能检测出这些对象。

# 三、YOLO-V3

# 四、YOLO-V4