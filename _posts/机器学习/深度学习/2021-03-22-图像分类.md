---
layout:     post                    # 使用的布局（不需要改）
title:      图像分类		    # 标题 
subtitle:   AlexNet、VGG、GoogLeNet、ResNet   	# 副标题
date:       2021-03-22              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - 深度学习
---
# 一、图像分类简介
图像分类实质上就是从给定的类别集合中为图像分配对应标签的任务。也就是说我们的任务是分析一个输入图像并返回一个该图像类别的标签

## 1. 常用数据集
### 1.1 mnist数据集
- 手写数字0-9的集合，共有60k训练图像、10k测试图像、10个类别、图像大小28×28×1
```python
from tensorflow.keras.datasets import mnist
# 加载mnist数据集

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

### 1.2 CIFAR-10和CIFAR-100
- CIFAR-10数据集5万张训练图像、1万张测试图像、10个类别、每个类别有6k个图像，图像大小32×32×3
- CIFAR-100数据集也是有5万张训练图像、1万张测试图像、包含100个类别、图像大小32×32×3。

```python
import tensorflow as tf
from tensorflow.keras.datasets import cifar10,cifar100
# 加载Cifar10数据集

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
# 加载Cifar100数据集

(train_images, train_labels), (test_images, test_labels)= cifar100.load_data()
```

### 1.3 ImageNet
- 是ILSVRC竞赛使用的是数据集，由斯坦福大学李飞飞教授主导；
- 包含了超过1400万张全尺寸的有标记图片，大约有22000个类别的数据。

![](https://tva1.sinaimg.cn/large/008eGmZEly1gosvaeulwmj30ls0e4tab.jpg)

# 二、AlexNet
## 1. AlexNet的网络架构
![](https://tva1.sinaimg.cn/large/008eGmZEly1gosvbhql0rj30lo0jndkk.jpg)

```python
# 构建AlexNet模型

net = tf.keras.models.Sequential([
    # 卷积层：96个卷积核，卷积核为11*11，步幅为4，激活函数relu

    tf.keras.layers.Conv2D(filters=96,kernel_size=11,strides=4,activation='relu'),
    # 池化:窗口大小为3*3、步幅为2

    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
    # 卷积层：256个卷积核，卷积核为5*5，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=256,kernel_size=5,padding='same',activation='relu'),
    # 池化:窗口大小为3*3、步幅为2

    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
    # 卷积层：384个卷积核，卷积核为3*3，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),
    # 卷积层：384个卷积核，卷积核为3*3，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),
    # 卷积层：256个卷积核，卷积核为3*3，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'),
    # 池化:窗口大小为3*3、步幅为2

    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
    # 伸展为1维向量

    tf.keras.layers.Flatten(),
    # 全连接层:4096个神经元，激活函数relu

    tf.keras.layers.Dense(4096,activation='relu'),
    # 随机失活

    tf.keras.layers.Dropout(0.5),
    # 全链接层：4096个神经元，激活函数relu

    tf.keras.layers.Dense(4096,activation='relu'),
    # 随机失活

    tf.keras.layers.Dropout(0.5),
    # 输出层：10个神经元，激活函数softmax

    tf.keras.layers.Dense(10,activation='softmax')
])
```

## 2. 手写数字势识别

```python

# 1. 模型读取

import numpy as np
# 获取手写数字数据集

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
# 训练集数据维度的调整：N H W C

train_images = np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))
# 测试集数据维度的调整：N H W C

test_images = np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))

# 2. 模型编译

# 定义两个方法随机抽取部分样本演示

# 获取训练集数据

def get_train(size):
    # 随机生成要抽样的样本的索引

    index = np.random.randint(0, np.shape(train_images)[0], size)
    # 将这些数据resize成227*227大小

    resized_images = tf.image.resize_with_pad(train_images[index],227,227,)
    # 返回抽取的

    return resized_images.numpy(), train_labels[index]
# 获取测试集数据 

def get_test(size):
    # 随机生成要抽样的样本的索引

    index = np.random.randint(0, np.shape(test_images)[0], size)
    # 将这些数据resize成227*227大小

    resized_images = tf.image.resize_with_pad(test_images[index],227,227,)
    # 返回抽样的测试样本

    return resized_images.numpy(), test_labels[index]

# 获取训练样本和测试样本

train_images,train_labels = get_train(256)
test_images,test_labels = get_test(128)

# 数据展示：将数据集的前九个数据集进行展示

for i in range(9):
    plt.subplot(3,3,i+1)
    # 以灰度图显示，不进行插值

    plt.imshow(train_images[i].astype(np.int8).squeeze(), cmap='gray', interpolation='none')
    # 设置图片的标题：对应的类别

    plt.title("数字{}".format(train_labels[i]))

# 指定优化器，损失函数和评价指标

optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)

net.compile(optimizer=optimizer,
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 3. 模型训练：指定训练数据，batchsize,epoch,验证集

net.fit(train_images,train_labels,batch_size=128,epochs=3,verbose=1,validation_split=0.1)

# 4. 模型评估
net.evaluate(test_images,test_labels,verbose=1)   
```

# 三、VGG
## 1. VGG的网络架构
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotp9j5jb1j30lh0gjgpq.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotpakiqlkj30lp08vtae.jpg)

```python
# 定义VGG网络中的卷积块：卷积层的个数，卷积层中卷积核的个数

def vgg_block(num_convs, num_filters):
    # 构建序列模型

    blk = tf.keras.models.Sequential()
    # 遍历所有的卷积层

    for _ in range(num_convs):
        # 每个卷积层：num_filter个卷积核，卷积核大小为3*3，padding是same，激活函数是relu

        blk.add(tf.keras.layers.Conv2D(num_filters,kernel_size=3,
                                    padding='same',activation='relu'))
    # 卷积块最后是一个最大池化，窗口大小为2*2，步长为2

    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
    return blk

# 定义VGG网络

def vgg(conv_arch):
    # 构建序列模型

    net = tf.keras.models.Sequential()
    # 根据conv_arch生成卷积部分

    for (num_convs, num_filters) in conv_arch:
        net.add(vgg_block(num_convs, num_filters))
    # 卷积块序列后添加全连接层

    net.add(tf.keras.models.Sequential([
        # 将特征图展成一维向量

        tf.keras.layers.Flatten(),
        # 全连接层：4096个神经元，激活函数是relu

        tf.keras.layers.Dense(4096, activation='relu'),
        # 随机失活

        tf.keras.layers.Dropout(0.5),
        # 全连接层：4096个神经元，激活函数是relu

        tf.keras.layers.Dense(4096, activation='relu'),
        # 随机失活

        tf.keras.layers.Dropout(0.5),
        # 全连接层：10个神经元，激活函数是softmax

        tf.keras.layers.Dense(10, activation='softmax')]))
    return net

# 网络实例化

net = vgg(conv_arch)

# 构造输入X，并将其送入到net网络中

X = tf.random.uniform((1,224,224,1))
y = net(X)
# 通过net.summay()查看网络的形状

net.summay()
```

# 四、GoogLeNet
## 1. Inception 块

## 2. GoogLeNet模型

# 五、ResNet

# 六、图像增强方法

# 七、模型微调