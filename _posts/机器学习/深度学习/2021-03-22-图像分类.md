---
layout:     post                    # 使用的布局（不需要改）
title:      图像分类		    # 标题 
subtitle:   AlexNet、VGG、GoogLeNet、ResNet   	# 副标题
date:       2021-03-22              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - 深度学习
---
# 一、图像分类简介
图像分类实质上就是从给定的类别集合中为图像分配对应标签的任务。也就是说我们的任务是分析一个输入图像并返回一个该图像类别的标签

## 1. 常用数据集
### 1.1 mnist数据集
- 手写数字0-9的集合，共有60k训练图像、10k测试图像、10个类别、图像大小28×28×1

```python
from tensorflow.keras.datasets import mnist
# 加载mnist数据集

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

### 1.2 CIFAR-10和CIFAR-100
- CIFAR-10数据集5万张训练图像、1万张测试图像、10个类别、每个类别有6k个图像，图像大小32×32×3
- CIFAR-100数据集也是有5万张训练图像、1万张测试图像、包含100个类别、图像大小32×32×3。

```python
import tensorflow as tf
from tensorflow.keras.datasets import cifar10,cifar100
# 加载Cifar10数据集

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
# 加载Cifar100数据集

(train_images, train_labels), (test_images, test_labels)= cifar100.load_data()
```

### 1.3 ImageNet
- 是ILSVRC竞赛使用的是数据集，由斯坦福大学李飞飞教授主导；
- 包含了超过1400万张全尺寸的有标记图片，大约有22000个类别的数据。

![](https://tva1.sinaimg.cn/large/008eGmZEly1gosvaeulwmj30ls0e4tab.jpg)

# 二、AlexNet
## 1. AlexNet的网络架构
![](https://tva1.sinaimg.cn/large/008eGmZEly1gosvbhql0rj30lo0jndkk.jpg)

```python
# 构建AlexNet模型

net = tf.keras.models.Sequential([
    # 卷积层：96个卷积核，卷积核为11*11，步幅为4，激活函数relu

    tf.keras.layers.Conv2D(filters=96,kernel_size=11,strides=4,activation='relu'),
    # 池化:窗口大小为3*3、步幅为2

    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
    # 卷积层：256个卷积核，卷积核为5*5，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=256,kernel_size=5,padding='same',activation='relu'),
    # 池化:窗口大小为3*3、步幅为2

    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
    # 卷积层：384个卷积核，卷积核为3*3，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),
    # 卷积层：384个卷积核，卷积核为3*3，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),
    # 卷积层：256个卷积核，卷积核为3*3，步幅为1，padding为same，激活函数relu

    tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'),
    # 池化:窗口大小为3*3、步幅为2

    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
    # 伸展为1维向量

    tf.keras.layers.Flatten(),
    # 全连接层:4096个神经元，激活函数relu

    tf.keras.layers.Dense(4096,activation='relu'),
    # 随机失活

    tf.keras.layers.Dropout(0.5),
    # 全链接层：4096个神经元，激活函数relu

    tf.keras.layers.Dense(4096,activation='relu'),
    # 随机失活

    tf.keras.layers.Dropout(0.5),
    # 输出层：10个神经元，激活函数softmax

    tf.keras.layers.Dense(10,activation='softmax')
])
```

## 2. 手写数字势识别

```python

# 1. 模型读取

import numpy as np
# 获取手写数字数据集

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
# 训练集数据维度的调整：N H W C

train_images = np.reshape(train_images,(train_images.shape[0],train_images.shape[1],train_images.shape[2],1))
# 测试集数据维度的调整：N H W C

test_images = np.reshape(test_images,(test_images.shape[0],test_images.shape[1],test_images.shape[2],1))

# 2. 模型编译

# 定义两个方法随机抽取部分样本演示

# 获取训练集数据

def get_train(size):
    # 随机生成要抽样的样本的索引

    index = np.random.randint(0, np.shape(train_images)[0], size)
    # 将这些数据resize成227*227大小

    resized_images = tf.image.resize_with_pad(train_images[index],227,227,)
    # 返回抽取的

    return resized_images.numpy(), train_labels[index]
# 获取测试集数据 

def get_test(size):
    # 随机生成要抽样的样本的索引

    index = np.random.randint(0, np.shape(test_images)[0], size)
    # 将这些数据resize成227*227大小

    resized_images = tf.image.resize_with_pad(test_images[index],227,227,)
    # 返回抽样的测试样本

    return resized_images.numpy(), test_labels[index]

# 获取训练样本和测试样本

train_images,train_labels = get_train(256)
test_images,test_labels = get_test(128)

# 数据展示：将数据集的前九个数据集进行展示

for i in range(9):
    plt.subplot(3,3,i+1)
    # 以灰度图显示，不进行插值

    plt.imshow(train_images[i].astype(np.int8).squeeze(), cmap='gray', interpolation='none')
    # 设置图片的标题：对应的类别

    plt.title("数字{}".format(train_labels[i]))

# 指定优化器，损失函数和评价指标

optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)

net.compile(optimizer=optimizer,
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 3. 模型训练：指定训练数据，batchsize,epoch,验证集

net.fit(train_images,train_labels,batch_size=128,epochs=3,verbose=1,validation_split=0.1)

# 4. 模型评估
net.evaluate(test_images,test_labels,verbose=1)   
```

# 三、VGG
## 1. VGG的网络架构
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotp9j5jb1j30lh0gjgpq.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotpakiqlkj30lp08vtae.jpg)

```python
# 定义VGG网络中的卷积块：卷积层的个数，卷积层中卷积核的个数

def vgg_block(num_convs, num_filters):
    # 构建序列模型

    blk = tf.keras.models.Sequential()
    # 遍历所有的卷积层

    for _ in range(num_convs):
        # 每个卷积层：num_filter个卷积核，卷积核大小为3*3，padding是same，激活函数是relu

        blk.add(tf.keras.layers.Conv2D(num_filters,kernel_size=3,
                                    padding='same',activation='relu'))
    # 卷积块最后是一个最大池化，窗口大小为2*2，步长为2

    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
    return blk

# 定义VGG网络

def vgg(conv_arch):
    # 构建序列模型

    net = tf.keras.models.Sequential()
    # 根据conv_arch生成卷积部分

    for (num_convs, num_filters) in conv_arch:
        net.add(vgg_block(num_convs, num_filters))
    # 卷积块序列后添加全连接层

    net.add(tf.keras.models.Sequential([
        # 将特征图展成一维向量

        tf.keras.layers.Flatten(),
        # 全连接层：4096个神经元，激活函数是relu

        tf.keras.layers.Dense(4096, activation='relu'),
        # 随机失活

        tf.keras.layers.Dropout(0.5),
        # 全连接层：4096个神经元，激活函数是relu

        tf.keras.layers.Dense(4096, activation='relu'),
        # 随机失活

        tf.keras.layers.Dropout(0.5),
        # 全连接层：10个神经元，激活函数是softmax

        tf.keras.layers.Dense(10, activation='softmax')]))
    return net

# 网络实例化

net = vgg(conv_arch)

# 构造输入X，并将其送入到net网络中

X = tf.random.uniform((1,224,224,1))
y = net(X)
# 通过net.summay()查看网络的形状

net.summay()
```

# 四、GoogLeNet
## 1. Inception 块
![](https://tva1.sinaimg.cn/large/008eGmZEly1goty6byc8hj30lk0gyq6k.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1goty6p0v6lj30m70cugn4.jpg)

```python
# 定义Inception模块

class Inception(tf.keras.layers.Layer):
    # 输入参数为各个卷积的卷积核个数

    def __init__(self, c1, c2, c3, c4):
        super().__init__()
        # 线路1：1 x 1卷积层，激活函数是RELU，padding是same

        self.p1_1 = tf.keras.layers.Conv2D(
            c1, kernel_size=1, activation='relu', padding='same')
        # 线路2，1 x 1卷积层后接3 x 3卷积层,激活函数是RELU，padding是same

        self.p2_1 = tf.keras.layers.Conv2D(
            c2[0], kernel_size=1, padding='same', activation='relu')
        self.p2_2 = tf.keras.layers.Conv2D(c2[1], kernel_size=3, padding='same',
                                           activation='relu')
        # 线路3，1 x 1卷积层后接5 x 5卷积层,激活函数是RELU，padding是same

        self.p3_1 = tf.keras.layers.Conv2D(
            c3[0], kernel_size=1, padding='same', activation='relu')
        self.p3_2 = tf.keras.layers.Conv2D(c3[1], kernel_size=5, padding='same',
                                           activation='relu')
        # 线路4，3 x 3最大池化层后接1 x 1卷积层,激活函数是RELU，padding是same

        self.p4_1 = tf.keras.layers.MaxPool2D(
            pool_size=3, padding='same', strides=1)
        self.p4_2 = tf.keras.layers.Conv2D(
            c4, kernel_size=1, padding='same', activation='relu')
    # 完成前向传播过程

    def call(self, x):
        # 线路1

        p1 = self.p1_1(x)
        # 线路2

        p2 = self.p2_2(self.p2_1(x))
        # 线路3

        p3 = self.p3_2(self.p3_1(x))
        # 线路4

        p4 = self.p4_2(self.p4_1(x))
        # 在通道维上concat输出

        outputs = tf.concat([p1, p2, p3, p4], axis=-1)
        return outputs  
```

## 2. GoogLeNet模型
![](https://tva1.sinaimg.cn/large/008eGmZEly1goty7pedcbj30lq0iigsq.jpg)

### 2.1 B1模块
第一模块使用一个64通道的7\*7卷积层。

```python
# 定义模型的输入

inputs = tf.keras.Input(shape=(224,224,3),name = "input")
# b1 模块
# 卷积层7*7的卷积核，步长为2，pad是same，激活函数RELU

x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')(inputs)
# 最大池化：窗口大小为3*3，步长为2，pad是same

x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
```

### 2.2 B2模块
第二模块使用2个卷积层：首先是64通道的1\*1,卷积层，然后是将通道增大3倍的3\*3卷积层
```python
# b2 模块
# 卷积层1*1的卷积核，步长为2，pad是same，激活函数RELU

x = tf.keras.layers.Conv2D(64, kernel_size=1, padding='same', activation='relu')(x)
# 卷积层3*3的卷积核，步长为2，pad是same，激活函数RELU

x = tf.keras.layers.Conv2D(192, kernel_size=3, padding='same', activation='relu')(x)
# 最大池化：窗口大小为3*3，步长为2，pad是same

x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
```
### 2.3 B3模块
第三模块串联2个完整的Inception块。第一个Inception块的输出通道数为64+128+32+32=256。第二个Inception块输出通道数增至128+192+96+64=480。

```python
# b3 模块
# Inception

x = Inception(64, (96, 128), (16, 32), 32)(x)
# Inception

x = Inception(128, (128, 192), (32, 96), 64)(x)
# 最大池化：窗口大小为3*3，步长为2，pad是same

x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
```
### 2.4 B4模块
> 增加辅助分类器是为了防止深度过深导致梯度消失；

![](https://tva1.sinaimg.cn/large/008eGmZEly1gotyb84btvj30lu09y76d.jpg)
```python
def aux_classifier(x, filter_size):
    #x:输入数据，filter_size:卷积层卷积核个数，全连接层神经元个数
    # 池化层

    x = tf.keras.layers.AveragePooling2D(
        pool_size=5, strides=3, padding='same')(x)
    # 1x1 卷积层

    x = tf.keras.layers.Conv2D(filters=filter_size[0], kernel_size=1, strides=1,
                               padding='valid', activation='relu')(x)
    # 展平

    x = tf.keras.layers.Flatten()(x)
    # 全连接层1

    x = tf.keras.layers.Dense(units=filter_size[1], activation='relu')(x)
    # softmax输出层

    x = tf.keras.layers.Dense(units=10, activation='softmax')(x)
    return x

# b4 模块
# Inception

x = Inception(192, (96, 208), (16, 48), 64)(x)
# 辅助输出1

aux_output_1 = aux_classifier(x, [128, 1024])
# Inception

x = Inception(160, (112, 224), (24, 64), 64)(x)
# Inception

x = Inception(128, (128, 256), (24, 64), 64)(x)
# Inception

x = Inception(112, (144, 288), (32, 64), 64)(x)
# 辅助输出2

aux_output_2 = aux_classifier(x, [128, 1024])
# Inception

x = Inception(256, (160, 320), (32, 128), 128)(x)
# 最大池化

x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
```
### 2.5 B5模块
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotyc8nra1j30lp0bfdjw.jpg)
```python
# b5 模块
# Inception

x = Inception(256, (160, 320), (32, 128), 128)(x)
# Inception

x = Inception(384, (192, 384), (48, 128), 128)(x)
# GAP

x = tf.keras.layers.GlobalAvgPool2D()(x)
# 输出层

main_outputs = tf.keras.layers.Dense(10,activation='softmax')(x)


# 使用Model来创建模型，指明输入和输出

model = tf.keras.Model(inputs=inputs, outputs=[main_outputs,aux_output_1，aux_output_2]) 
model.summary()
```
## 3. 延伸版本
### 3.1 InceptionV2
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotyel1r9ij30ma0c2juw.jpg)

### 3.2 InceptionV3
![](https://tva1.sinaimg.cn/large/008eGmZEly1gotyf34l6pj30lb0mfgps.jpg)

# 五、ResNet


# 六、图像增强方法
## 1. 常用的图像增强方法 
- 图像增强（image augmentation）：
    - 指通过剪切、旋转/反射/翻转变换、缩放变换、平移变换、尺度变换、对比度变换、噪声扰动、颜色变换等一种或多种组合数据增强变换的方式来增加数据集的大小。
- 常见的图像增强方式可以分为两类：
    - 几何变换类
    - 颜色变换类

![](https://tva1.sinaimg.cn/large/008eGmZEly1gotyhs3bhyj30lp0mz4qi.jpg)

## 2. tf.image进行图像增强
### 2.1 翻转和裁剪
```python
# 左右翻转并显示

cat1 = tf.image.random_flip_left_right(cat)
plt.imshow(cat1）

# 上下翻转

cat2 = tf.image.random_flip_up_down(cat)
plt.imshow(cat2)

# 随机裁剪

cat3 = tf.image.random_crop(cat,(200,200,3))
plt.imshow(cat3)
```
### 2.2 颜色变换  
```python
# 亮度随机变化

cat4=tf.image.random_brightness(cat,0.5)
plt.imshow(cat4)

# 变化图像的色调

cat5 = tf.image.random_hue(cat,0.5)
plt.imshow(cat5)
```

## 3. 使用ImageDataGenerator()进行图像增强


# 七、模型微调