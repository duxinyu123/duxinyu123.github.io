---
layout:     post                    # 使用的布局（不需要改）
title:      EM算法  			    # 标题 
subtitle:     				# 副标题
date:       2021-03-04              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - 机器学习
---

# 一、算法介绍
## 1. 算法原理
EM算法也称期望最大化(Expectation-Maximum,简称EM)算法。 它是一个基础算法，是很多机器学习领域算法的基础，比如隐式马尔科夫算法(HMM)等等。 EM算法是一种迭代优化策略，由于它的计算方法中每一次迭代都分两步，
其中一个为期望步(E步)， 另一个为极大步(M步)，
所以算法被称为EM算法(Expectation-Maximization Algorithm)。

## 2. 算法流程
![](https://tva1.sinaimg.cn/large/e6c9d24ely1go7m3ekn4xj21d50u0qh2.jpg)

- E步：根据当前的参数计算条件概率（期望）；
- M步：计算使得当前似然函数取得极大值时的参数值作为下一次迭代的参数；
- 如此往复，直至参数的变化很小或者不变，说明当前得到的参数为最优解

## 3. 极大似然估计
![](https://tva1.sinaimg.cn/large/e6c9d24ely1go7m4c65yaj21980u0dwf.jpg)

### 3.1 似然和概率
![](https://tva1.sinaimg.cn/large/e6c9d24ely1go7mr7dlslj21ey0ii7la.jpg)

- 概率是evaluation问题
- 似然是learning问题

## 4. EM 算法推导过程
![](https://tva1.sinaimg.cn/large/008eGmZEly1go8185sptcj30xz0u0ah5.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1go81879xmtj30zk0u0wkn.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1go8184gl9qj315a0kywh1.jpg)
