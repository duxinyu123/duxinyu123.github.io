---
layout:     post                    # 使用的布局（不需要改）
title:      K-近邻算法   			    # 标题 		  
subtitle:   K值选择、距离度量、分类决策  # 副标题
date:       2021-02-01              # 时间
author:     新宇                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               # 标签
    - 机器学习
---
> 要点：模型、策略(误分类率最小)、算法(构建kd树)

# 一、模型
## 1. 定义
![](https://tva1.sinaimg.cn/large/008eGmZEly1gn83nn6z64j30kf0dsk6u.jpg)

1. K Nearest Neighbor算法又叫KNN算法；俗语形容：**近朱者赤，近墨者黑**

2. 如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别；

## 2. 距离度量
1. 欧式距离(欧几里得)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gn83rkgffij30t60ju0yc.jpg)
![](https://tva1.sinaimg.cn/large/008eGmZEly1gn83rkog2oj31ae0hq12i.jpg)

2. Lp距离定义
![](https://tva1.sinaimg.cn/large/008eGmZEly1gn854lx3tuj314k0lqq91.jpg)

# 二、策略
## 1. K值如何选择

## 2. 分类决策规则

# 三、算法
## 1. 构造kd树

## 2. 搜索kd树


# 四、 API使用

1. Scikit-learn
	```sh
	# 安装Scikit-learn

	pip3 install scikit-learn==0.19.1
	```

3. API介绍
	- **sklearn.neighbors.KNeighborsClassifier**(n_neighbors=5)
		- n_neighbors:int,可选(默认= 5)，k_neighbors查询默认使用的邻居数

4. 代码实现
	```python
	from sklearn.neighbors import KNeighborsClassifier

	# 1.准备训练数据

	x = [[0],[1],[2],[60],[70],[80]]
	y = [0,0,0,1,1,1]

	# 2.实例化API

	n = KNeighborsClassifier(n_neighbors=2)

	# 3.训练模型

	n.fit(x,y)

	# 4.预测模型

	y_predict = n.predict([[10],[20],[30],[55],[75],[95]])
	print(y_predict)
	```

